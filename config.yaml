# config.yaml
# This file contains the default configuration

# Global setting
config_path: 'config.yaml'
machine_config_path: 'machine.yaml'
enable_seed: True  # apply seed globally
seed: 42
enable_rewrite_output_dir: True
output_dir: './output/p2_ded_bead_profile/v22.0'  # relative to data_root_dir
enable_uuid_naming: True # if false, use customized naming
extra_name: 'incremental.standardize.sample_1.enc_201_ah_0.label_6.b64.lr_0.4e-5_0.985.loss_008812'
#extra_name: 'enc_301_ah_200'
training_mode: 'default' # training model: 'default', 'epoch_time_test', 'seq_len_test', 'benchmark_test'

# Data
dataset_dir: './dataset/p2_ded_bead_profile/20240919'  # relative to data_root_dir
raw_timestamp_interval: 2.5  # ms
## Dataset and Dataloader
enable_iterate_dataset: True # iterate for all sub datasets in the dataset_dir
dataset_iterate_ratio: 1.0 # use only portion of the dataset
dataset_name: 'High_const_sin_1_dataset.pt' # 'simu_data' for random init, not used when enable_iterate_dataset == True
enable_deploy_dataset: False
dataset_exclude_for_deploy: ['Low_noise_noise_1_dataset.pt', 'Low_noise_noise_2_dataset.pt', 'Low_const_const_1_dataset.pt', 'Low_const_const_2_dataset.pt', 'High_sin_tooth_1_dataset.pt', 'High_sin_tooth_2_dataset.pt'] # used when enable_deploy_dataset == True
train_val_test_ratio: [0.8, 0.1, 0.1]
batch_size: 64
num_workers: 0  # no need to set if all data in GPU
## Special sampler/filter/modifier
sys_sampling_interval: 1  # systematic sampling interval <--------------------------------------------
enable_standardize_feature: True
enable_exclude_feature: True
enable_rtcp: 'both' # 'on_only', 'off_only' 'both'
## Sequence length
n_seq_enc_look_back: 200
n_seq_enc_look_ahead: 0
n_seq_enc_total: 201
n_seq_dec_look_back: 100
n_seq_dec_pool: 1   # pool size >= 1
## Feature / Img
enable_resnet_preprocess: True
img_crop_pixel: 350   # cropped from 480x440
img_input_size: 224   # resized the cropped img
img_start_idx: 0    # shift in starting index
## Feature / Parameter
param_start_idx: 6
param_size: 7   # number of expr. parameters
param_exclude: [5, 6] # to be excluded from param_size, start from 0
param_mean: []
param_std: []
# 1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0
## Feature / Positional
pos_start_idx: 0
pos_size: 15 # time, position, distance, etc.
pos_exclude: [] # to be excluded from pos_size, start from 0
pos_mean: []
pos_std: []
## Feature / Output
label_start_index: 13 # 0 for WHA, 7 for Sigmoid param, the rest for cropped data (13 for dataset 0823/later)
label_crop_size: 400  # 6 for wha, 400 for dataset 0823/later
label_size: 40  # 6 for wha, 40 for dataset 0823/later
label_noise_cutoff: 0.01
label_additional_noise: 0.05 # 0.05 means 5% more
## incremental learning setting
num_phases: 3
domain_order: ["const", "tooth", "sin", "square", "noise"]

# Model
model: "STEN_GP_BLSTM_FFD"  # None, STEN_GP_FA_TA, STEN_GP_FFD, STEN_GP_TA_FFD, STEN_GP_FFD_TA, STEN_GP_FFD_BLSTM
## initialization
enable_param_init: False  # default init method: kaiming_normal_
enable_preload_param: False
preload_param_path: '/home/ubuntu/Desktop/mydata/output/p2_ded_bead_profile/v13.2/241117-181146.2843.img_param_pos_111.standardize.sample_1.enc_201_ah_100.label_40.b64.blstm_ffd.lr_0.4e-5_0.985.loss_008812/best_model_wts.pth'
## embedding
feature_embed_option: 'default' # 'fc', 'default'
embed_preload_param: False
embed_require_grad: False  # --- ABLATION + Transfer learning
embed_dim: -1 # auto calculated
## embedding / Img
enable_img_embed: True   # --- ABLATION
img_embed_dim: 512    # number of conv. feature
## embedding / Parameter
enable_param_embed: True  # --- ABLATION
param_embed_dim: 6
## embedding / Positional
enable_pos_embed: True  # --- ABLATION
pos_embed_exclude: None
pos_embed_dim: 6
## encoder
encoder_preload_param: False
encoder_require_grad: False  # --- ABLATION + Transfer learning
encoder_layer_size: 1   # --- ABLATION
encoder_num_heads: 4
enable_residual_gamma: False   # --- ABLATION
enable_layer_norm: True
enable_dropout: True
dropout: 0.3
## decoder
decoder_preload_param: False
decoder_require_grad: True  # --- ABLATION + Transfer learning
decoder_option: 'default' # 'transformer'
output_size: 40
output_embed_dim: 6
## adaptor
enable_adaptor: False
adaptor_option: 'GMM3' # 'None', 'Fourier3', 'Sigmoid6'
adaptor_component_size: 10

# Training
## Scheduled sampling
enable_scheduled_sampling: False
scheduled_sampling_max_epoch: 20
## criterion
criterion_option: 'mae_mse_iou' # 'mse', 'iou', 'mse_iou', 'mae_mse_iou'
criterion_mae_lambda: 0.00
criterion_mse_lambda: 0.88
criterion_iou_lambda: 0.12
enable_early_stopping: False
## metric
metric_option: 'miou'  # 'mse', 'rmse', 'mape', 'mapa', 'mae', 'miou'
computation_eps: 1.0e-6
## optimizer
num_epochs: 100
optimizer_option: 'adam_Vaswani_2017' # 'adam', 'adamw', 'adam_Vaswani_2017'
lr: 0.4e-5  # learning rate 1.0e-4, 1.2e-4, 1.0e-7 for WHA prediction
enable_weight_decay: False
wd: 1.0e-4  # weight decay
enable_adaptive_lr: True
lr_gamma: 0.985  # lr reduction factor for each epoch 0.985, 0.96
lr_adaptive_max_epoch: 1000

# Checkpoint
checkpoint_dir: './'  # relative to output_dir
enable_save_best_model: True
enable_save_all_best_model: True
checkpoint_epoch_interval: 5

# Log
log_dir: './logs/'  # relative to output_dir
enable_tensorboard: True
enable_save_history_stats_to_csv: True
enable_save_attention: False