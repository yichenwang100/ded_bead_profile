# config.yaml
# This file contains the default configuration

# Global setting
config_path: 'config.yaml'
machine_config_path: 'machine.yaml'
enable_seed: True  # apply seed globally
seed: 42
enable_rewrite_output_dir: True
output_dir: './output/p2_ded_bead_profile/v19.9'  # relative to data_root_dir
enable_uuid_naming: True # if false, use customized naming
extra_name: 'param_5.standardize.sample_1.enc_201_ah_100.label_40.b64.blstm_ffd.lr_0.4e-5_0.985.loss_008812'
training_mode: 'default' # training model: 'epoch_time_test', 'seq_len_test', 'ablation_test'

# Data
dataset_dir: './dataset/p2_ded_bead_profile/20240919'  # relative to data_root_dir
raw_timestamp_interval: 2.5  # ms
## Dataset and Dataloader
enable_iterate_dataset: True # iterate for all sub datasets in the dataset_dir
dataset_iterate_ratio: 1.0 # use only portion of the dataset
dataset_name: 'High_const_sin_1_dataset.pt' # 'simu_data' for random init, not used when enable_iterate_dataset == True
enable_deploy_dataset: False
dataset_exclude_for_deploy: ['Low_noise_noise_1_dataset.pt', 'Low_noise_noise_2_dataset.pt', 'Low_const_const_1_dataset.pt', 'Low_const_const_2_dataset.pt', 'High_sin_tooth_1_dataset.pt', 'High_sin_tooth_2_dataset.pt'] # used when enable_deploy_dataset == True
train_val_test_ratio: [0.8, 0.1, 0.1]
batch_size: 64
num_workers: 0  # no need to set if all data in GPU
## Special sampler/filter/modifier
sys_sampling_interval: 1  # systematic sampling interval <--------------------------------------------
enable_standardize_feature: True
enable_exclude_feature: True
enable_rtcp: 'both' # 'on_only', 'off_only' 'both'
## Sequence length
n_seq_enc_look_back: 100
n_seq_enc_look_ahead: 100
n_seq_enc_total: 201
n_seq_dec_look_back: 100
n_seq_dec_pool: 1   # pool size >= 1
## Feature / Img
enable_resnet_preprocess: True
img_crop_pixel: 350   # cropped from 480x440
img_input_size: 224   # resized the cropped img
img_start_idx: 0    # shift in starting index
## Feature / Parameter
param_start_idx: 6
param_size: 7   # number of expr. parameters
param_exclude: [5, 6] # to be excluded from param_size, start from 0
param_mean: []
param_std: []
# 1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0
## Feature / Positional
pos_start_idx: 0
pos_size: 15 # time, position, distance, etc.
pos_exclude: [] # to be excluded from pos_size, start from 0
pos_mean: []
pos_std: []
## Feature / Output
label_start_index: 0 # 0 for WHA, 7 for Sigmoid param, the rest for cropped data (53 for data 0730, 13+ for 0823/later)
label_crop_size: 6  # 400 for dataset 0823/later, crop from the original 600 points
label_size: 6
label_noise_cutoff: 0.01

# Model
model: "STEN_GP_BLSTM_FFD"  # None, STEN_GP_FA_TA, STEN_GP_FFD, STEN_GP_TA_FFD, STEN_GP_FFD_TA, STEN_GP_FFD_BLSTM
## initialization
enable_param_init: False  # default init method: kaiming_normal_
enable_preload_param: True
preload_param_path: 'C:\mydata\output\p2_ded_bead_profile\v13.1\241031-193730.9630.param_5.standardize.sample_1.enc_201_ah_100.label_40.b64.blstm_ffd.lr_0.4e-5_0.985.loss_008812\best_model_wts.pth'
## embedding
feature_embed_option: 'default' # 'fc', 'default'
embed_preload_param: True
embed_require_grad: False  # --- ABLATION + Transfer learning
embed_dim: -1 # auto calculated
## embedding / Img
enable_img_embed: True   # --- ABLATION
img_embed_dim: 512    # number of conv. feature
## embedding / Parameter
enable_param_embed: True  # --- ABLATION
param_embed_dim: 6
## embedding / Positional
enable_pos_embed: True  # --- ABLATION
pos_embed_exclude: None
pos_embed_dim: 6
## encoder
encoder_preload_param: True
encoder_require_grad: False  # --- ABLATION + Transfer learning
encoder_layer_size: 1   # --- ABLATION
encoder_num_heads: 4
enable_residual_gamma: False   # --- ABLATION
enable_layer_norm: True
enable_dropout: True
dropout: 0.3
## decoder
decoder_preload_param: False
decoder_require_grad: True  # --- ABLATION + Transfer learning
decoder_option: 'default' # 'transformer'
output_size: 6
output_embed_dim: 6
## adaptor
enable_adaptor: False
adaptor_option: 'GMM3' # 'None', 'Fourier3', 'Sigmoid6'
adaptor_component_size: 10

# Training
## Scheduled sampling
enable_scheduled_sampling: False
scheduled_sampling_max_epoch: 20
## criterion
criterion_option: 'mse' # 'mse', 'iou', 'mse_iou', 'mae_mse_iou'
criterion_mae_lambda: 0.00
criterion_mse_lambda: 0.88
criterion_iou_lambda: 0.12
enable_early_stopping: False
## metric
metric_option: 'mapa'  # 'mse', 'rmse', 'mape', 'mapa', 'mae', 'miou'
computation_eps: 1.0e-6
## optimizer
num_epochs: 100
optimizer_option: 'adam_Vaswani_2017' # 'adam', 'adamw', 'adam_Vaswani_2017'
lr: 0.4e-5  # learning rate 1.0e-4, 1.2e-4
enable_weight_decay: False
wd: 1.0e-4  # weight decay
enable_adaptive_lr: True
lr_gamma: 0.985  # lr reduction factor for each epoch 0.985, 0.96
lr_adaptive_max_epoch: 1000

# Checkpoint
checkpoint_dir: './'  # relative to output_dir
enable_save_best_model: True
enable_save_all_best_model: True
checkpoint_epoch_interval: 5

# Log
log_dir: './logs/'  # relative to output_dir
enable_tensorboard: True
enable_save_history_stats_to_csv: True
enable_save_attention: False